{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed6adc511bfaa75c",
   "metadata": {},
   "source": [
    "# Adapter Training & QA Notebook\n",
    "\n",
    "Use this notebook to fine-tune a PEFT adapter with the repo's training stack and immediately validate it with the same grounding logic used by `/gen/ask`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cade2cd1b107c8",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "1. Configure training + ask parameters below (project/document IDs must exist in your Postgres DB).\n",
    "2. Toggle `RUN_TRAINING = True` to launch a new adapter run (or keep it `False` to reuse artifacts already in `TRAINING_CONFIG['output_dir']`).\n",
    "3. Use the last cell to ask grounded questions against the freshly trained adapter. Provide `MANUAL_CONTEXT` snippets if you want to bypass DB-backed retrieval.\n",
    "\n",
    "> Prereqs: run `make setup`, load `.env`, and keep Postgres/Redis/MinIO running (for example via `make dev` or `docker compose up`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232f9fa7d6c696f9",
   "metadata": {},
   "source": [
    "## Environment Setup & Shared MinIO\n",
    "\n",
    "- Use Python 3.11+. Create a venv and install deps before running the notebook:\n",
    "  - `python -m venv .venv && source .venv/bin/activate` (Windows: `..\\.venv\\Scripts\\activate`)\n",
    "  - `python -m pip install --upgrade pip`\n",
    "  - `pip install -r requirements.txt -r requirements-dev.txt`\n",
    "- Set `.env` (or export vars) so `DATABASE_URL`, `REDIS_URL`, etc. point at your infra.\n",
    "- Reuse the existing MinIO bucket by setting: `MINIO_ENDPOINT`, `MINIO_ACCESS_KEY`, `MINIO_SECRET_KEY`, `MINIO_SECURE`, and `S3_BUCKET`.\n",
    "  - The same bucket serves both training artifacts and `/gen/ask` adapters.\n",
    "  - Grant read/write perms; the notebook shell-outs to `train_adapter.py`, which uploads artifacts back to this bucket.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddbcfc3e9d4da16",
   "metadata": {},
   "source": [
    "## Separate Training vs Gen/Ask Flows\n",
    "\n",
    "- **Training cells**: configure `TRAINING_CONFIG` and toggle `RUN_TRAINING = True` when you want to fine-tune a new adapter.\n",
    "  - Outputs land in `TRAINING_CONFIG['output_dir']` locally and are pushed to MinIO via `train_adapter.py`.\n",
    "- **Gen/Ask cells**: keep `RUN_TRAINING = False` to skip re-training and load whichever adapter directory you specify.\n",
    "  - `ask_with_adapter` mirrors the `/gen/ask` microservice: it retrieves evidence from Postgres + MinIO, applies the adapter via `ModelService`, and shows grounding citations.\n",
    "- You can also run the real microservice separately: `python scripts/serve_local.py` (same `.env` + MinIO config).\n",
    "- For a full CLI runbook outside this notebook see `docs/local_training_and_gen_ask.md`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e282e8",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Setup and activation of virtual environment\n",
    "! pip install -U ipykernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af3c8aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'.venv' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 1)) (0.121.1)\n",
      "Requirement already satisfied: pydantic-settings in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 3)) (2.11.0)\n",
      "Requirement already satisfied: sqlalchemy in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 4)) (2.0.44)\n",
      "Requirement already satisfied: alembic in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 5)) (1.17.1)\n",
      "Requirement already satisfied: boto3 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 6)) (1.40.69)\n",
      "Requirement already satisfied: celery in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 7)) (5.5.3)\n",
      "Requirement already satisfied: redis in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 8)) (7.0.1)\n",
      "Requirement already satisfied: flower==2.0.1 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 9)) (2.0.1)\n",
      "Requirement already satisfied: python-multipart in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 10)) (0.0.20)\n",
      "Requirement already satisfied: httpx in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 11)) (0.28.1)\n",
      "Requirement already satisfied: PyMuPDF in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 12)) (1.26.6)\n",
      "Requirement already satisfied: beautifulsoup4 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 13)) (4.14.2)\n",
      "Requirement already satisfied: jinja2 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 14)) (3.1.6)\n",
      "Requirement already satisfied: psycopg2-binary in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 15)) (2.9.11)\n",
      "Requirement already satisfied: pytesseract in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 16)) (0.3.13)\n",
      "Requirement already satisfied: charset-normalizer in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 17)) (3.4.4)\n",
      "Requirement already satisfied: lxml in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 18)) (6.0.2)\n",
      "Requirement already satisfied: pyarrow in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 19)) (22.0.0)\n",
      "Requirement already satisfied: datasets in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 20)) (4.4.1)\n",
      "Requirement already satisfied: langdetect in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 21)) (1.0.9)\n",
      "Requirement already satisfied: prometheus-client==0.18.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 22)) (0.18.0)\n",
      "Requirement already satisfied: eval_type_backport in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 23)) (0.2.2)\n",
      "Requirement already satisfied: faiss-cpu in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 25)) (1.12.0)\n",
      "Requirement already satisfied: sentence-transformers in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 26)) (5.1.2)\n",
      "Requirement already satisfied: transformers in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 27)) (4.57.1)\n",
      "Requirement already satisfied: accelerate in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 28)) (1.11.0)\n",
      "Requirement already satisfied: trl in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 29)) (0.25.0)\n",
      "Requirement already satisfied: peft in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 30)) (0.17.1)\n",
      "Requirement already satisfied: bitsandbytes in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 31)) (0.48.2)\n",
      "Requirement already satisfied: torch in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 32)) (2.9.0)\n",
      "Requirement already satisfied: rwkv in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 33)) (0.8.30)\n",
      "Requirement already satisfied: llama-cpp-python in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 34)) (0.3.16)\n",
      "Requirement already satisfied: black in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements-dev.txt (line 1)) (25.9.0)\n",
      "Requirement already satisfied: isort in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements-dev.txt (line 2)) (7.0.0)\n",
      "Requirement already satisfied: mypy in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements-dev.txt (line 3)) (1.18.2)\n",
      "Requirement already satisfied: coverage in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements-dev.txt (line 4)) (7.11.2)\n",
      "Requirement already satisfied: coverage-badge in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements-dev.txt (line 5)) (1.1.2)\n",
      "Requirement already satisfied: pytest in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements-dev.txt (line 6)) (9.0.0)\n",
      "Requirement already satisfied: pre-commit in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements-dev.txt (line 7)) (4.4.0)\n",
      "Requirement already satisfied: uvicorn[standard] in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements.txt (line 2)) (0.38.0)\n",
      "Requirement already satisfied: moto[s3] in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from -r f:/Learning/InstructifyAI/requirements-dev.txt (line 8)) (5.1.16)\n",
      "Requirement already satisfied: tornado<7.0.0,>=5.0.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from flower==2.0.1->-r f:/Learning/InstructifyAI/requirements.txt (line 9)) (6.5.2)\n",
      "Requirement already satisfied: humanize in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from flower==2.0.1->-r f:/Learning/InstructifyAI/requirements.txt (line 9)) (4.14.0)\n",
      "Requirement already satisfied: pytz in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from flower==2.0.1->-r f:/Learning/InstructifyAI/requirements.txt (line 9)) (2025.2)\n",
      "Requirement already satisfied: starlette<0.50.0,>=0.40.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from fastapi->-r f:/Learning/InstructifyAI/requirements.txt (line 1)) (0.49.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from fastapi->-r f:/Learning/InstructifyAI/requirements.txt (line 1)) (2.12.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from fastapi->-r f:/Learning/InstructifyAI/requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from fastapi->-r f:/Learning/InstructifyAI/requirements.txt (line 1)) (0.0.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->-r f:/Learning/InstructifyAI/requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->-r f:/Learning/InstructifyAI/requirements.txt (line 1)) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->-r f:/Learning/InstructifyAI/requirements.txt (line 1)) (0.4.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from starlette<0.50.0,>=0.40.0->fastapi->-r f:/Learning/InstructifyAI/requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi->-r f:/Learning/InstructifyAI/requirements.txt (line 1)) (3.11)\n",
      "Requirement already satisfied: sniffio>=1.1 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi->-r f:/Learning/InstructifyAI/requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: click>=7.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from uvicorn[standard]->-r f:/Learning/InstructifyAI/requirements.txt (line 2)) (8.3.0)\n",
      "Requirement already satisfied: h11>=0.8 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from uvicorn[standard]->-r f:/Learning/InstructifyAI/requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: colorama>=0.4 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from uvicorn[standard]->-r f:/Learning/InstructifyAI/requirements.txt (line 2)) (0.4.6)\n",
      "Requirement already satisfied: httptools>=0.6.3 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from uvicorn[standard]->-r f:/Learning/InstructifyAI/requirements.txt (line 2)) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from uvicorn[standard]->-r f:/Learning/InstructifyAI/requirements.txt (line 2)) (1.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from uvicorn[standard]->-r f:/Learning/InstructifyAI/requirements.txt (line 2)) (6.0.3)\n",
      "Requirement already satisfied: watchfiles>=0.13 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from uvicorn[standard]->-r f:/Learning/InstructifyAI/requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from uvicorn[standard]->-r f:/Learning/InstructifyAI/requirements.txt (line 2)) (15.0.1)\n",
      "Requirement already satisfied: greenlet>=1 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from sqlalchemy->-r f:/Learning/InstructifyAI/requirements.txt (line 4)) (3.2.4)\n",
      "Requirement already satisfied: Mako in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from alembic->-r f:/Learning/InstructifyAI/requirements.txt (line 5)) (1.3.10)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.69 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from boto3->-r f:/Learning/InstructifyAI/requirements.txt (line 6)) (1.40.69)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from boto3->-r f:/Learning/InstructifyAI/requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from boto3->-r f:/Learning/InstructifyAI/requirements.txt (line 6)) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from botocore<1.41.0,>=1.40.69->boto3->-r f:/Learning/InstructifyAI/requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from botocore<1.41.0,>=1.40.69->boto3->-r f:/Learning/InstructifyAI/requirements.txt (line 6)) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.69->boto3->-r f:/Learning/InstructifyAI/requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: billiard<5.0,>=4.2.1 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from celery->-r f:/Learning/InstructifyAI/requirements.txt (line 7)) (4.2.2)\n",
      "Requirement already satisfied: kombu<5.6,>=5.5.2 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from celery->-r f:/Learning/InstructifyAI/requirements.txt (line 7)) (5.5.4)\n",
      "Requirement already satisfied: vine<6.0,>=5.1.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from celery->-r f:/Learning/InstructifyAI/requirements.txt (line 7)) (5.1.0)\n",
      "Requirement already satisfied: click-didyoumean>=0.3.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from celery->-r f:/Learning/InstructifyAI/requirements.txt (line 7)) (0.3.1)\n",
      "Requirement already satisfied: click-repl>=0.2.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from celery->-r f:/Learning/InstructifyAI/requirements.txt (line 7)) (0.3.0)\n",
      "Requirement already satisfied: click-plugins>=1.1.1 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from celery->-r f:/Learning/InstructifyAI/requirements.txt (line 7)) (1.1.1.2)\n",
      "Requirement already satisfied: amqp<6.0.0,>=5.1.1 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from kombu<5.6,>=5.5.2->celery->-r f:/Learning/InstructifyAI/requirements.txt (line 7)) (5.3.1)\n",
      "Requirement already satisfied: tzdata>=2025.2 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from kombu<5.6,>=5.5.2->celery->-r f:/Learning/InstructifyAI/requirements.txt (line 7)) (2025.2)\n",
      "Requirement already satisfied: packaging in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from kombu<5.6,>=5.5.2->celery->-r f:/Learning/InstructifyAI/requirements.txt (line 7)) (25.0)\n",
      "Requirement already satisfied: certifi in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from httpx->-r f:/Learning/InstructifyAI/requirements.txt (line 11)) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from httpx->-r f:/Learning/InstructifyAI/requirements.txt (line 11)) (1.0.9)\n",
      "Requirement already satisfied: soupsieve>1.2 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from beautifulsoup4->-r f:/Learning/InstructifyAI/requirements.txt (line 13)) (2.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from jinja2->-r f:/Learning/InstructifyAI/requirements.txt (line 14)) (3.0.3)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from pytesseract->-r f:/Learning/InstructifyAI/requirements.txt (line 16)) (12.0.0)\n",
      "Requirement already satisfied: filelock in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (2.3.4)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (0.4.0)\n",
      "Requirement already satisfied: pandas in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (4.67.1)\n",
      "Requirement already satisfied: xxhash in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (0.36.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (3.13.2)\n",
      "Requirement already satisfied: scikit-learn in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from sentence-transformers->-r f:/Learning/InstructifyAI/requirements.txt (line 26)) (1.7.2)\n",
      "Requirement already satisfied: scipy in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from sentence-transformers->-r f:/Learning/InstructifyAI/requirements.txt (line 26)) (1.16.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from transformers->-r f:/Learning/InstructifyAI/requirements.txt (line 27)) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from transformers->-r f:/Learning/InstructifyAI/requirements.txt (line 27)) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from transformers->-r f:/Learning/InstructifyAI/requirements.txt (line 27)) (0.6.2)\n",
      "Requirement already satisfied: psutil in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from accelerate->-r f:/Learning/InstructifyAI/requirements.txt (line 28)) (7.1.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from torch->-r f:/Learning/InstructifyAI/requirements.txt (line 32)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from torch->-r f:/Learning/InstructifyAI/requirements.txt (line 32)) (3.5)\n",
      "Requirement already satisfied: setuptools in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from torch->-r f:/Learning/InstructifyAI/requirements.txt (line 32)) (80.9.0)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from llama-cpp-python->-r f:/Learning/InstructifyAI/requirements.txt (line 34)) (5.6.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from black->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from black->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from black->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 1)) (4.5.0)\n",
      "Requirement already satisfied: pytokens>=0.1.10 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from black->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: iniconfig>=1.0.1 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from pytest->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from pytest->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 6)) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from pytest->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 6)) (2.19.2)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from pre-commit->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 7)) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from pre-commit->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 7)) (2.6.15)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from pre-commit->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 7)) (1.9.1)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from pre-commit->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 7)) (20.35.4)\n",
      "Requirement already satisfied: cryptography>=35.0.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from moto[s3]->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 8)) (46.0.3)\n",
      "Requirement already satisfied: xmltodict in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from moto[s3]->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 8)) (1.0.2)\n",
      "Requirement already satisfied: werkzeug!=2.2.0,!=2.2.1,>=0.5 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from moto[s3]->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 8)) (3.1.3)\n",
      "Requirement already satisfied: responses!=0.25.5,>=0.15.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from moto[s3]->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 8)) (0.25.8)\n",
      "Requirement already satisfied: py-partiql-parser==0.6.3 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from moto[s3]->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 8)) (0.6.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r f:/Learning/InstructifyAI/requirements.txt (line 20)) (1.22.0)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.36 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from click-repl>=0.2.0->celery->-r f:/Learning/InstructifyAI/requirements.txt (line 7)) (3.0.52)\n",
      "Requirement already satisfied: cffi>=2.0.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from cryptography>=35.0.0->moto[s3]->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 8)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from cffi>=2.0.0->cryptography>=35.0.0->moto[s3]->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 8)) (2.23)\n",
      "Requirement already satisfied: wcwidth in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery->-r f:/Learning/InstructifyAI/requirements.txt (line 7)) (0.2.14)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch->-r f:/Learning/InstructifyAI/requirements.txt (line 32)) (1.3.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit->-r f:/Learning/InstructifyAI/requirements-dev.txt (line 7)) (0.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers->-r f:/Learning/InstructifyAI/requirements.txt (line 26)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in f:\\learning\\instructifyai\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers->-r f:/Learning/InstructifyAI/requirements.txt (line 26)) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "! .venv/Scripts/activate\n",
    "! python -m pip install -r f:/Learning/InstructifyAI/requirements.txt -r f:/Learning/InstructifyAI/requirements-dev.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7944a7df",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root on sys.path: f:\\Learning\\InstructifyAI\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "REPO_ROOT = Path.cwd().parent\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "print(\"Repo root on sys.path:\", REPO_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3e9f3904332cd4f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env='DEV' database_url='postgresql+psycopg2://labeler:labeler@localhost:5432/labeler' redis_url='redis://redis:6379/0' minio_endpoint='localhost:9000' minio_access_key='minioadmin' minio_secret_key='minioadmin' minio_secure=False s3_bucket='labeler-dev' export_signed_url_expiry_seconds=600 suggestion_timeout_ms=500 max_suggestions_per_doc=200 ocr_langs=[] min_text_len_for_ocr=0 html_crawl_max_depth=2 html_crawl_max_pages=10 curation_completeness_threshold=0.8 empty_chunk_ratio_threshold=0.1 html_section_path_coverage_threshold=0.9 text_coverage_threshold=0.5 ocr_ratio_threshold=0.5 utf_other_ratio_threshold=0.2 jwt_secret='change-me' jwt_public_key=None rate_limit_window_seconds=60 rate_limit_max_per_minute=60 tables_as_text=False ls_base_url='http://localhost:8080' ls_api_token='changeme' enable_adapters_api=False feature_doc_bindings=True ocr_backend='tesseract' feature_deepseek_ocr=False deepseek_ocr_runtime='transformers' deepseek_ocr_model='deepseek-ai/DeepSeek-OCR' adapter_cache_dir=None max_active_adapters=4 gen_evidence_top_k=3 gen_default_prompt=None gen_fallback_answer='No grounded answer available.' gen_retry_on_missing_citations=True gen_min_rank_score=0.15\n",
      "Repo root: f:\\Learning\\InstructifyAI\n",
      "Database driver: postgresql+psycopg2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amit\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_config.py:383: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'validate_by_name'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import textwrap\n",
    "\n",
    "from core.settings import get_settings\n",
    "from tools.notebook_runner import ask_with_adapter, ensure_adapter_dir, run_training_job\n",
    "\n",
    "settings = get_settings()\n",
    "print(settings)\n",
    "db_scheme = settings.database_url.split(\"://\", 1)[0]\n",
    "print(f\"Repo root: {REPO_ROOT}\")\n",
    "print(f\"Database driver: {db_scheme}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abab3de470681130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "document_id_gen = \"f33d29ea-5935-4606-8342-c4e11496f63f\"\n",
    "snap_path = REPO_ROOT / \"snapshot.jsonl\"\n",
    "\n",
    "BASE_TRAINING_CONFIG = {\n",
    "    \"mode\": \"sft\",  # choices: sft, mft, or orpo\n",
    "    \"project_id\": \"df9031dc-93b0-4617-8b78-54fbbe74160f\",\n",
    "    \"base_model\": \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    \"dataset_path\": snap_path,\n",
    "    \"output_dir\": \"outputs/notebook_adapter\",\n",
    "    \"epochs\": 1,\n",
    "    \"lr\": 2e-4,\n",
    "    \"batch_size\": 1,\n",
    "    \"grad_accum\": 8,\n",
    "    \"max_seq_len\": 1024,\n",
    "    \"quantization\": \"int4\",\n",
    "    \"peft\": \"lora\",\n",
    "    \"document_id\": document_id_gen,\n",
    "    \"python\": r\"F:\\Learning\\InstructifyAI\\.venv\\Scripts\\python.exe\",\n",
    "}\n",
    "\n",
    "# Define quick experiment variants with low epochs for smoke tests\n",
    "EXPERIMENTS = [\n",
    "    {\n",
    "        \"name\": \"int4_lr2e-4\",\n",
    "        \"overrides\": {\n",
    "            \"epochs\": 1,\n",
    "            \"quantization\": \"int4\",\n",
    "            \"lr\": 2e-4,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"fp16_lr1e-4\",\n",
    "        \"overrides\": {\n",
    "            \"epochs\": 3,\n",
    "            \"quantization\": \"fp16\",\n",
    "            \"lr\": 1e-4,\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "def prepare_experiments(base_cfg: dict, exp_defs: list[dict]) -> list[dict]:\n",
    "    runs: list[dict] = []\n",
    "    base_output = Path(base_cfg[\"output_dir\"])\n",
    "    for item in exp_defs:\n",
    "        cfg = deepcopy(base_cfg)\n",
    "        overrides = item.get(\"overrides\") or {}\n",
    "        cfg.update(overrides)\n",
    "        cfg[\"output_dir\"] = str((base_output / item[\"name\"]).resolve())\n",
    "        runs.append({\"name\": item[\"name\"], \"config\": cfg})\n",
    "    return runs\n",
    "\n",
    "TRAINING_RUNS = prepare_experiments(BASE_TRAINING_CONFIG, EXPERIMENTS)\n",
    "\n",
    "ASK_CONFIG = {\n",
    "    \"project_id\": BASE_TRAINING_CONFIG[\"project_id\"],\n",
    "    \"document_id\": BASE_TRAINING_CONFIG.get(\"document_id\"),\n",
    "    \"base_model\": BASE_TRAINING_CONFIG[\"base_model\"],\n",
    "    \"question\": \"Summarize the key binary classification task .\",\n",
    "    \"top_k\": 3,\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_new_tokens\": 400,\n",
    "}\n",
    "\n",
    "RUN_TRAINING = False  # flip to True to train all experiments in sequence\n",
    "MANUAL_CONTEXT: list[str] = []  # add free-form context strings to bypass DB retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f226ddaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared experiments:\n",
      "- int4_lr2e-4: epochs=1 lr=0.0002 quant=int4 peft=lora output=F:\\Learning\\InstructifyAI\\notebooks\\outputs\\notebook_adapter\\int4_lr2e-4\n",
      "- fp16_lr1e-4: epochs=3 lr=0.0001 quant=fp16 peft=lora output=F:\\Learning\\InstructifyAI\\notebooks\\outputs\\notebook_adapter\\fp16_lr1e-4\n",
      "PyTorch: 2.7.1+cu128 CUDA: 12.8\n",
      "Primary GPU: NVIDIA GeForce RTX 5060 Ti\n",
      "Capability: (12, 0)\n"
     ]
    }
   ],
   "source": [
    "print(\"Prepared experiments:\")\n",
    "for run in TRAINING_RUNS:\n",
    "    cfg = run[\"config\"]\n",
    "    print(\n",
    "        f\"- {run['name']}: epochs={cfg['epochs']} lr={cfg['lr']} quant={cfg['quantization']} \"\n",
    "        f\"peft={cfg['peft']} output={cfg['output_dir']}\"\n",
    "    )\n",
    "\n",
    "import torch\n",
    "print(\"PyTorch:\", torch.__version__, \"CUDA:\", torch.version.cuda)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Primary GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Capability:\", torch.cuda.get_device_capability(0))\n",
    "else:\n",
    "    print(\"CUDA not available; generation will run on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64806974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mm secs: 0.2164325714111328\n",
      "capability: (12, 0)\n",
      "localhost:9000\n"
     ]
    }
   ],
   "source": [
    "import torch, time\n",
    "assert torch.cuda.is_available()\n",
    "x = torch.randn(8192, 8192, device='cuda')\n",
    "t0 = time.time(); y = x @ x; torch.cuda.synchronize(); print(\"mm secs:\", time.time()-t0)\n",
    "print(\"capability:\", torch.cuda.get_device_capability(0))\n",
    "import os\n",
    "os.environ[\"MINIO_ENDPOINT\"] = \"localhost:9000\"  # make sure the env var is correct\n",
    "\n",
    "from core import settings as core_settings\n",
    "core_settings.get_settings.cache_clear()          # drop the cached Settings instance\n",
    "print(core_settings.get_settings().minio_endpoint)  # should now print localhost:9000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "711ac253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from core import settings as core_settings\n",
    "\n",
    "os.environ[\"POSTGRES_HOST\"] = \"localhost\"\n",
    "os.environ[\"DATABASE_URL\"] = \"postgresql+psycopg2://labeler:labeler@localhost:5432/labeler\"\n",
    "core_settings.get_settings.cache_clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a233aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping training; set RUN_TRAINING = True to fine-tune adapters.\n",
      "[int4_lr2e-4] Adapter directory ready: F:\\Learning\\InstructifyAI\\notebooks\\outputs\\notebook_adapter\\int4_lr2e-4\\adapter\n",
      "[fp16_lr1e-4] Adapter directory ready: F:\\Learning\\InstructifyAI\\notebooks\\outputs\\notebook_adapter\\fp16_lr1e-4\\adapter\n"
     ]
    }
   ],
   "source": [
    "for run in TRAINING_RUNS:\n",
    "    run.pop(\"summary\", None)\n",
    "    run.pop(\"adapter_dir\", None)\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    for run in TRAINING_RUNS:\n",
    "        print(f\"\\n=== Training {run['name']} ===\")\n",
    "        run[\"summary\"] = run_training_job(run[\"config\"])\n",
    "else:\n",
    "    print(\"Skipping training; set RUN_TRAINING = True to fine-tune adapters.\")\n",
    "\n",
    "for run in TRAINING_RUNS:\n",
    "    output_root = ensure_adapter_dir(run[\"config\"])\n",
    "    adapter_dir = Path(output_root) / \"adapter\"\n",
    "    if not adapter_dir.exists():\n",
    "        raise FileNotFoundError(f\"Adapter payload missing at {adapter_dir}\")\n",
    "    run[\"adapter_dir\"] = adapter_dir\n",
    "    print(f\"[{run['name']}] Adapter directory ready: {adapter_dir}\")\n",
    "    summary = run.get(\"summary\")\n",
    "    if summary:\n",
    "        print(\"  Payload:\", summary.get(\"result\"))\n",
    "        log_path = summary.get(\"log_path\")\n",
    "        if log_path:\n",
    "            print(f\"  Training log: {log_path}\")\n",
    "        tail = \"\".join(summary.get(\"log_tail\") or [])\n",
    "        if tail:\n",
    "            print(\"  Captured output tail:\")\n",
    "            print(tail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04882d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql+psycopg2://labeler:labeler@localhost:5432/labeler\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from core import settings as core_settings\n",
    "\n",
    "os.environ[\"POSTGRES_HOST\"] = \"localhost\"\n",
    "os.environ[\"DATABASE_URL\"] = \"postgresql+psycopg2://labeler:labeler@localhost:5432/labeler\"\n",
    "core_settings.get_settings.cache_clear()\n",
    "print(core_settings.get_settings().database_url)  # sanity check\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "81967342124791da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Benchmarking int4_lr2e-4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amit\\AppData\\Roaming\\Python\\Python312\\site-packages\\peft\\tuners\\tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "C:\\Users\\amit\\AppData\\Roaming\\Python\\Python312\\site-packages\\peft\\peft_model.py:585: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.mlp.down_proj.lora_magnitude_vector.default.weight'].\n",
      "  warnings.warn(warn_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer (wrapped to 100 chars):\n",
      "The binary classification task involves using the softmax function to compute class probabilities\n",
      "from the neural network's output, ensalled by the argmax function for class label prediction. The\n",
      "softmax function normalizes the output of the network to ensure the sum of probabilities equals 1,\n",
      "which is essential for interpreting the network's output as class probabilities (6a6b2bde-\n",
      "ce69-5504-be91-9e2e71dc1fe9). For multi-class classification, the one-versus-rest (OvA) method\n",
      "extends binary classifiers to handle multiple classes by training a separate classifier for each\n",
      "class, assigning the class with the highest confidence score (49253f48-b666-5c03-acde-3d2484e44acc).\n",
      "The backward method in the NeuralNetMLP class computes gradients for the loss function, which are\n",
      "used for updating the network's parameters via gradient descent\n",
      "(bc2e58fd-45f5-5427-8ae1-2e90d81279ff).   Document:  - [6a6b2bde-ce69-5504-be91-9e2e71dc1fe9]\n",
      "Context   Parallelizing Neural Network Training with PyTorch 40 After training a neural network with\n",
      "PyTorch, we can use the softmax function to convert the network's output into class probabilities.\n",
      "However, the output does not sum to 1, which is a problem for interpreting the network's output as\n",
      "class probabilities. Nevertheless, this is not a significant issue if we only use the network to\n",
      "predict class labels and not the class probabilities. One way to obtain class labels from the\n",
      "- [6a6b2bde-ce69-5504-be91-9e2e71dc1fe9] order=424 rank=0.646\n",
      "- [49253f48-b666-5c03-acde-3d2484e44acc] order=56 rank=0.625\n",
      "- [bc2e58fd-45f5-5427-8ae1-2e90d81279ff] order=372 rank=0.613\n",
      "=== Benchmarking fp16_lr1e-4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amit\\AppData\\Roaming\\Python\\Python312\\site-packages\\peft\\peft_model.py:585: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.28.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.29.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.30.mlp.down_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.o_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.qkv_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.qkv_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.qkv_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.mlp.gate_up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.mlp.gate_up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.mlp.gate_up_proj.lora_magnitude_vector.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.31.mlp.down_proj.lora_magnitude_vector.default.weight'].\n",
      "  warnings.warn(warn_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer (wrapped to 100 chars):\n",
      "The binary classification task involves using the softmax function to compute class probabilities\n",
      "from the neural network's output, ensalled by the argmax function for class label prediction. The\n",
      "softmax function normalizes the output of the network to ensure the sum of probabilities equals 1,\n",
      "which is essential for interpreting the network's output as class probabilities (6a6b2bde-\n",
      "ce69-5504-be91-9e2e71dc1fe9). For multi-class classification, the one-versus-rest (OvA) method\n",
      "extends binary classifiers to handle multiple classes by training a separate classifier for each\n",
      "class, assigning the class with the highest confidence score (49253f48-b666-5c03-acde-3d2484e44acc).\n",
      "The backward method in the NeuralNetMLP class computes gradients for the loss function, which are\n",
      "used for updating the network's parameters via gradient descent\n",
      "(bc2e58fd-45f5-5427-8ae1-2e90d81279ff).   Document:  - [6a6b2bde-ce69-5504-be91-9e2e71dc1fe9]\n",
      "Context   Parallelizing Neural Network Training with PyTorch 40 After training a neural network with\n",
      "PyTorch, we can use the softmax function to convert the network's output into class probabilities.\n",
      "However, the output does not sum to 1, which is a problem for interpreting the network's output as\n",
      "class probabilities. Nevertheless, this is not a significant issue if we only use the network to\n",
      "predict class labels and not the class probabilities. One way to obtain class labels from the\n",
      "- [6a6b2bde-ce69-5504-be91-9e2e71dc1fe9] order=424 rank=0.646\n",
      "- [49253f48-b666-5c03-acde-3d2484e44acc] order=56 rank=0.625\n",
      "- [bc2e58fd-45f5-5427-8ae1-2e90d81279ff] order=372 rank=0.613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'int4_lr2e-4',\n",
       "  'answer': \"The binary classification task involves using the softmax function to compute class probabilities from the neural network's output, ensalled by the argmax function for class label prediction. The softmax function normalizes the output of the network to ensure the sum of probabilities equals 1, which is essential for interpreting the network's output as class probabilities (6a6b2bde-ce69-5504-be91-9e2e71dc1fe9). For multi-class classification, the one-versus-rest (OvA) method extends binary classifiers to handle multiple classes by training a separate classifier for each class, assigning the class with the highest confidence score (49253f48-b666-5c03-acde-3d2484e44acc). The backward method in the NeuralNetMLP class computes gradients for the loss function, which are used for updating the network's parameters via gradient descent (bc2e58fd-45f5-5427-8ae1-2e90d81279ff).\\n\\n\\nDocument:\\n\\n- [6a6b2bde-ce69-5504-be91-9e2e71dc1fe9] Context\\n  Parallelizing Neural Network Training with PyTorch 40 After training a neural network with PyTorch, we can use the softmax function to convert the network's output into class probabilities. However, the output does not sum to 1, which is a problem for interpreting the network's output as class probabilities. Nevertheless, this is not a significant issue if we only use the network to predict class labels and not the class probabilities. One way to obtain class labels from the\",\n",
       "  'citations': [{'chunk_id': '6a6b2bde-ce69-5504-be91-9e2e71dc1fe9',\n",
       "    'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "    'section_path': [],\n",
       "    'order': 424,\n",
       "    'score': 0.37638697028160095,\n",
       "    'rank_score': 0.646386970281601,\n",
       "    'excerpt': 'Parallelizing Neural Network Training with PyTorch 402 As you can see in the output, the resulting values cannot be interpreted as probabilities for a three-class problem. The reason for this is that they do not sum to 1. However, this is, in fact, not a big concern if we use our model to predict only the class labels and not the class membership probabilities. One way to predict the class label from the output units obtained earlier is to use the maximum value: >>> y_class = np.argmax(Z, axis=0'},\n",
       "   {'chunk_id': '49253f48-b666-5c03-acde-3d2484e44acc',\n",
       "    'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "    'section_path': [],\n",
       "    'order': 56,\n",
       "    'score': 0.3547772169113159,\n",
       "    'rank_score': 0.6247772169113159,\n",
       "    'excerpt': \"Training Simple Machine Learning Algorithms for Classification 30 First, we will use the pandas library to load the Iris dataset directly from the UCI Machine Learning Repository into a DataFrame object and print the last five lines via the tail method to check that the data was loaded correctly: >>> import os >>> import pandas as pd >>> s = 'https://archive.ics.uci.edu/ml/'\\\\ ... 'machine-learning-databases/iris/iris.data' >>> print('From URL:', s) From URL: https://archive.ics.uci.edu/ml/machin\"},\n",
       "   {'chunk_id': 'bc2e58fd-45f5-5427-8ae1-2e90d81279ff',\n",
       "    'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "    'section_path': [],\n",
       "    'order': 372,\n",
       "    'score': 0.37614548206329346,\n",
       "    'rank_score': 0.6128121487299601,\n",
       "    'excerpt': 'Implementing a Multilayer Artificial Neural Network from Scratch 350 ################################# # Part 2: dLoss/dHiddenWeights ## = DeltaOut * dOutNet/dHiddenAct * dHiddenAct/dHiddenNet # * dHiddenNet/dWeight # [n_classes, n_hidden] d_z_out__a_h = self.weight_out # output dim: [n_examples, n_hidden] d_loss__a_h = np.dot(delta_out, d_z_out__a_h) # [n_examples, n_hidden] d_a_h__d_z_h = a_h * (1. - a_h) # sigmoid derivative # [n_examples, n_features] d_z_h__d_w_h = x # output dim: [n_hidden,'}],\n",
       "  'raw': {'answer': \"The binary classification task involves using the softmax function to compute class probabilities from the neural network's output, ensalled by the argmax function for class label prediction. The softmax function normalizes the output of the network to ensure the sum of probabilities equals 1, which is essential for interpreting the network's output as class probabilities (6a6b2bde-ce69-5504-be91-9e2e71dc1fe9). For multi-class classification, the one-versus-rest (OvA) method extends binary classifiers to handle multiple classes by training a separate classifier for each class, assigning the class with the highest confidence score (49253f48-b666-5c03-acde-3d2484e44acc). The backward method in the NeuralNetMLP class computes gradients for the loss function, which are used for updating the network's parameters via gradient descent (bc2e58fd-45f5-5427-8ae1-2e90d81279ff).\\n\\n\\nDocument:\\n\\n- [6a6b2bde-ce69-5504-be91-9e2e71dc1fe9] Context\\n  Parallelizing Neural Network Training with PyTorch 40 After training a neural network with PyTorch, we can use the softmax function to convert the network's output into class probabilities. However, the output does not sum to 1, which is a problem for interpreting the network's output as class probabilities. Nevertheless, this is not a significant issue if we only use the network to predict class labels and not the class probabilities. One way to obtain class labels from the\",\n",
       "   'citations': [{'chunk_id': '6a6b2bde-ce69-5504-be91-9e2e71dc1fe9',\n",
       "     'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "     'section_path': [],\n",
       "     'order': 424,\n",
       "     'score': 0.37638697028160095,\n",
       "     'rank_score': 0.646386970281601,\n",
       "     'excerpt': 'Parallelizing Neural Network Training with PyTorch 402 As you can see in the output, the resulting values cannot be interpreted as probabilities for a three-class problem. The reason for this is that they do not sum to 1. However, this is, in fact, not a big concern if we use our model to predict only the class labels and not the class membership probabilities. One way to predict the class label from the output units obtained earlier is to use the maximum value: >>> y_class = np.argmax(Z, axis=0'},\n",
       "    {'chunk_id': '49253f48-b666-5c03-acde-3d2484e44acc',\n",
       "     'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "     'section_path': [],\n",
       "     'order': 56,\n",
       "     'score': 0.3547772169113159,\n",
       "     'rank_score': 0.6247772169113159,\n",
       "     'excerpt': \"Training Simple Machine Learning Algorithms for Classification 30 First, we will use the pandas library to load the Iris dataset directly from the UCI Machine Learning Repository into a DataFrame object and print the last five lines via the tail method to check that the data was loaded correctly: >>> import os >>> import pandas as pd >>> s = 'https://archive.ics.uci.edu/ml/'\\\\ ... 'machine-learning-databases/iris/iris.data' >>> print('From URL:', s) From URL: https://archive.ics.uci.edu/ml/machin\"},\n",
       "    {'chunk_id': 'bc2e58fd-45f5-5427-8ae1-2e90d81279ff',\n",
       "     'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "     'section_path': [],\n",
       "     'order': 372,\n",
       "     'score': 0.37614548206329346,\n",
       "     'rank_score': 0.6128121487299601,\n",
       "     'excerpt': 'Implementing a Multilayer Artificial Neural Network from Scratch 350 ################################# # Part 2: dLoss/dHiddenWeights ## = DeltaOut * dOutNet/dHiddenAct * dHiddenAct/dHiddenNet # * dHiddenNet/dWeight # [n_classes, n_hidden] d_z_out__a_h = self.weight_out # output dim: [n_examples, n_hidden] d_loss__a_h = np.dot(delta_out, d_z_out__a_h) # [n_examples, n_hidden] d_a_h__d_z_h = a_h * (1. - a_h) # sigmoid derivative # [n_examples, n_features] d_z_h__d_w_h = x # output dim: [n_hidden,'}],\n",
       "   'prompt': \"Context:\\n- [6a6b2bde-ce69-5504-be91-9e2e71dc1fe9] Context\\n  Parallelizing Neural Network Training with PyTorch 402 As you can see in the output, the resulting values cannot be interpreted as probabilities for a three-class problem. The reason for this is that they do not sum to 1. However, this is, in fact, not a big concern if we use our model to predict only the class labels and not the class membership probabilities. One way to predict the class label from the output units obtained earlier is to use the maximum value: >>> y_class = np.argmax(Z, axis=0) >>> print('Predicted class label:', y_class) Predicted class label: 0 In certain contexts, it can be useful to compute meaningful class probabilities for multiclass predic- tions. In the next section, we will take a look at a generalization of the logistic function, the softmax function, which can help us with this task. Estimating class probabilities in multiclass classification via the softmax function In the previous section, you saw how we can obtain a class label using the argmax function. Previously, in the Building a multilayer perceptron for classifying flowers in the Iris dataset section, we determined activation='softmax' in the last layer of the MLP model. The softmax function is a soft form of the argmax function; instead of giving a single class index, it provides the probability of each class. Therefore, it allows us to compute meaningful class probabilities in multiclass settings (multinomial logistic regression). In softmax, the probability of a particular sample with net input z belonging to the ith class can be computed with a normalization term in the denominator, that is, the sum of the exponentially weighted linear functions: () = () =      To see softmax in action, lets code it up in Python: >>> def softmax(z): ... return np.exp(z) / np.sum(np.exp(z)) >>> y_probas = softmax(Z) >>> print('Probabilities:\\\\n', y_probas) Probabilities: [ 0.44668973 0.16107406 0.39223621] >>> np.sum(y_probas) 1.0 As you can see, the predicted class probabilities now sum to 1, as we would expect. It is also notable that the predicted class label is the same as when we applied the argmax function to the logistic output.\\n- [49253f48-b666-5c03-acde-3d2484e44acc] Context\\n  Training Simple Machine Learning Algorithms for Classification 30 First, we will use the pandas library to load the Iris dataset directly from the UCI Machine Learning Repository into a DataFrame object and print the last five lines via the tail method to check that the data was loaded correctly: >>> import os >>> import pandas as pd >>> s = 'https://archive.ics.uci.edu/ml/'\\\\ ... 'machine-learning-databases/iris/iris.data' >>> print('From URL:', s) From URL: https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris. data >>> df = pd.read_csv(s, ... header=None, ... encoding='utf-8') >>> df.tail() After executing the previous code, we should see the following output, which shows the last five lines of the Iris dataset: Figure 2.5: The last five lines of the Iris dataset The OvA method for multi-class classification OvA, which is sometimes also called one-versus-rest (OvR), is a technique that allows us to extend any binary classifier to multi-class problems. Using OvA, we can train one classifier per class, where the particular class is treated as the positive class and the examples from all other classes are considered negative classes. If we were to classify a new, unlabeled data instance, we would use our n classifiers, where n is the number of class labels, and assign the class label with the highest confidence to the particular instance we want to classify. In the case of the perceptron, we would use OvA to choose the class label that is associated with the largest absolute net input value.\\n- [bc2e58fd-45f5-5427-8ae1-2e90d81279ff] Context\\n  Implementing a Multilayer Artificial Neural Network from Scratch 350 ################################# # Part 2: dLoss/dHiddenWeights ## = DeltaOut * dOutNet/dHiddenAct * dHiddenAct/dHiddenNet # * dHiddenNet/dWeight # [n_classes, n_hidden] d_z_out__a_h = self.weight_out # output dim: [n_examples, n_hidden] d_loss__a_h = np.dot(delta_out, d_z_out__a_h) # [n_examples, n_hidden] d_a_h__d_z_h = a_h * (1. - a_h) # sigmoid derivative # [n_examples, n_features] d_z_h__d_w_h = x # output dim: [n_hidden, n_features] d_loss__d_w_h = np.dot((d_loss__a_h * d_a_h__d_z_h).T, d_z_h__d_w_h) d_loss__d_b_h = np.sum((d_loss__a_h * d_a_h__d_z_h), axis=0) return (d_loss__dw_out, d_loss__db_out, d_loss__d_w_h, d_loss__d_b_h) The backward method implements the so-called backpropagation algorithm, which calculates the gra- dients of the loss with respect to the weight and bias parameters. Similar to Adaline, these gradients are then used to update these parameters via gradient descent. Note that multilayer NNs are more complex than their single-layer siblings, and we will go over the mathematical concepts of how to compute the gradients in a later section after discussing the code. For now, just consider the backward method as a way for computing gradients that are used for the gradient descent updates. For simplic- ity, the loss function this derivation is based on is the same MSE loss that we used in Adaline. In later chapters, we will look at alternative loss functions, such as multi-category cross-entropy loss, which is a generalization of the binary logistic regression loss to multiple classes. Looking at this code implementation of the NeuralNetMLP class, you may have noticed that this object-oriented implementation differs from the familiar scikit-learn API that is centered around the .fit() and .predict() methods. Instead, the main methods of the NeuralNetMLP class are the .forward() and .backward() methods. One of the reasons behind this is that it makes a complex neu- ral network a bit easier to understand in terms of how the information flows through the networks.\\n\\nQuestion: Summarize the key binary classification task .\\n\\nAnswer in at most four sentences and cite sources using [chunk_id].\",\n",
       "   'system_prompt': 'You are a precise assistant. Use only the provided context to answer. Respond succinctly, cite sources using their [chunk_id] identifiers, and do not introduce facts that are not present in the context.',\n",
       "   'evidence': [{'chunk_id': '6a6b2bde-ce69-5504-be91-9e2e71dc1fe9',\n",
       "     'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "     'order': 424,\n",
       "     'text': \"Parallelizing Neural Network Training with PyTorch 402 As you can see in the output, the resulting values cannot be interpreted as probabilities for a three-class problem. The reason for this is that they do not sum to 1. However, this is, in fact, not a big concern if we use our model to predict only the class labels and not the class membership probabilities. One way to predict the class label from the output units obtained earlier is to use the maximum value: >>> y_class = np.argmax(Z, axis=0) >>> print('Predicted class label:', y_class) Predicted class label: 0 In certain contexts, it can be useful to compute meaningful class probabilities for multiclass predic- tions. In the next section, we will take a look at a generalization of the logistic function, the softmax function, which can help us with this task. Estimating class probabilities in multiclass classification via the softmax function In the previous section, you saw how we can obtain a class label using the argmax function. Previously, in the Building a multilayer perceptron for classifying flowers in the Iris dataset section, we determined activation='softmax' in the last layer of the MLP model. The softmax function is a soft form of the argmax function; instead of giving a single class index, it provides the probability of each class. Therefore, it allows us to compute meaningful class probabilities in multiclass settings (multinomial logistic regression). In softmax, the probability of a particular sample with net input z belonging to the ith class can be computed with a normalization term in the denominator, that is, the sum of the exponentially weighted linear functions: () = () =      To see softmax in action, lets code it up in Python: >>> def softmax(z): ... return np.exp(z) / np.sum(np.exp(z)) >>> y_probas = softmax(Z) >>> print('Probabilities:\\\\n', y_probas) Probabilities: [ 0.44668973 0.16107406 0.39223621] >>> np.sum(y_probas) 1.0 As you can see, the predicted class probabilities now sum to 1, as we would expect. It is also notable that the predicted class label is the same as when we applied the argmax function to the logistic output.\",\n",
       "     'section_path': [],\n",
       "     'text_hash': 'f4d29b06a3c96a45c2aaf84a230fb3a9975640b77586cf8ca0e5c6741637bdd2',\n",
       "     'score': 0.37638697028160095,\n",
       "     'rank_score': 0.646386970281601},\n",
       "    {'chunk_id': '49253f48-b666-5c03-acde-3d2484e44acc',\n",
       "     'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "     'order': 56,\n",
       "     'text': \"Training Simple Machine Learning Algorithms for Classification 30 First, we will use the pandas library to load the Iris dataset directly from the UCI Machine Learning Repository into a DataFrame object and print the last five lines via the tail method to check that the data was loaded correctly: >>> import os >>> import pandas as pd >>> s = 'https://archive.ics.uci.edu/ml/'\\\\ ... 'machine-learning-databases/iris/iris.data' >>> print('From URL:', s) From URL: https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris. data >>> df = pd.read_csv(s, ... header=None, ... encoding='utf-8') >>> df.tail() After executing the previous code, we should see the following output, which shows the last five lines of the Iris dataset: Figure 2.5: The last five lines of the Iris dataset The OvA method for multi-class classification OvA, which is sometimes also called one-versus-rest (OvR), is a technique that allows us to extend any binary classifier to multi-class problems. Using OvA, we can train one classifier per class, where the particular class is treated as the positive class and the examples from all other classes are considered negative classes. If we were to classify a new, unlabeled data instance, we would use our n classifiers, where n is the number of class labels, and assign the class label with the highest confidence to the particular instance we want to classify. In the case of the perceptron, we would use OvA to choose the class label that is associated with the largest absolute net input value.\",\n",
       "     'section_path': [],\n",
       "     'text_hash': 'f66ea4b7d32d6a9341dcc3ac1d396ffb38420dd22c2efb5e8174746a1d9464b1',\n",
       "     'score': 0.3547772169113159,\n",
       "     'rank_score': 0.6247772169113159},\n",
       "    {'chunk_id': 'bc2e58fd-45f5-5427-8ae1-2e90d81279ff',\n",
       "     'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "     'order': 372,\n",
       "     'text': 'Implementing a Multilayer Artificial Neural Network from Scratch 350 ################################# # Part 2: dLoss/dHiddenWeights ## = DeltaOut * dOutNet/dHiddenAct * dHiddenAct/dHiddenNet # * dHiddenNet/dWeight # [n_classes, n_hidden] d_z_out__a_h = self.weight_out # output dim: [n_examples, n_hidden] d_loss__a_h = np.dot(delta_out, d_z_out__a_h) # [n_examples, n_hidden] d_a_h__d_z_h = a_h * (1. - a_h) # sigmoid derivative # [n_examples, n_features] d_z_h__d_w_h = x # output dim: [n_hidden, n_features] d_loss__d_w_h = np.dot((d_loss__a_h * d_a_h__d_z_h).T, d_z_h__d_w_h) d_loss__d_b_h = np.sum((d_loss__a_h * d_a_h__d_z_h), axis=0) return (d_loss__dw_out, d_loss__db_out, d_loss__d_w_h, d_loss__d_b_h) The backward method implements the so-called backpropagation algorithm, which calculates the gra- dients of the loss with respect to the weight and bias parameters. Similar to Adaline, these gradients are then used to update these parameters via gradient descent. Note that multilayer NNs are more complex than their single-layer siblings, and we will go over the mathematical concepts of how to compute the gradients in a later section after discussing the code. For now, just consider the backward method as a way for computing gradients that are used for the gradient descent updates. For simplic- ity, the loss function this derivation is based on is the same MSE loss that we used in Adaline. In later chapters, we will look at alternative loss functions, such as multi-category cross-entropy loss, which is a generalization of the binary logistic regression loss to multiple classes. Looking at this code implementation of the NeuralNetMLP class, you may have noticed that this object-oriented implementation differs from the familiar scikit-learn API that is centered around the .fit() and .predict() methods. Instead, the main methods of the NeuralNetMLP class are the .forward() and .backward() methods. One of the reasons behind this is that it makes a complex neu- ral network a bit easier to understand in terms of how the information flows through the networks.',\n",
       "     'section_path': [],\n",
       "     'text_hash': '052c60f6dd5f60e8a31732174fe8e6ac84314f5d24bd580b25a1d563547365e6',\n",
       "     'score': 0.37614548206329346,\n",
       "     'rank_score': 0.6128121487299601}]}},\n",
       " {'name': 'fp16_lr1e-4',\n",
       "  'answer': \"The binary classification task involves using the softmax function to compute class probabilities from the neural network's output, ensalled by the argmax function for class label prediction. The softmax function normalizes the output of the network to ensure the sum of probabilities equals 1, which is essential for interpreting the network's output as class probabilities (6a6b2bde-ce69-5504-be91-9e2e71dc1fe9). For multi-class classification, the one-versus-rest (OvA) method extends binary classifiers to handle multiple classes by training a separate classifier for each class, assigning the class with the highest confidence score (49253f48-b666-5c03-acde-3d2484e44acc). The backward method in the NeuralNetMLP class computes gradients for the loss function, which are used for updating the network's parameters via gradient descent (bc2e58fd-45f5-5427-8ae1-2e90d81279ff).\\n\\n\\nDocument:\\n\\n- [6a6b2bde-ce69-5504-be91-9e2e71dc1fe9] Context\\n  Parallelizing Neural Network Training with PyTorch 40 After training a neural network with PyTorch, we can use the softmax function to convert the network's output into class probabilities. However, the output does not sum to 1, which is a problem for interpreting the network's output as class probabilities. Nevertheless, this is not a significant issue if we only use the network to predict class labels and not the class probabilities. One way to obtain class labels from the\",\n",
       "  'citations': [{'chunk_id': '6a6b2bde-ce69-5504-be91-9e2e71dc1fe9',\n",
       "    'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "    'section_path': [],\n",
       "    'order': 424,\n",
       "    'score': 0.37638697028160095,\n",
       "    'rank_score': 0.646386970281601,\n",
       "    'excerpt': 'Parallelizing Neural Network Training with PyTorch 402 As you can see in the output, the resulting values cannot be interpreted as probabilities for a three-class problem. The reason for this is that they do not sum to 1. However, this is, in fact, not a big concern if we use our model to predict only the class labels and not the class membership probabilities. One way to predict the class label from the output units obtained earlier is to use the maximum value: >>> y_class = np.argmax(Z, axis=0'},\n",
       "   {'chunk_id': '49253f48-b666-5c03-acde-3d2484e44acc',\n",
       "    'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "    'section_path': [],\n",
       "    'order': 56,\n",
       "    'score': 0.3547772169113159,\n",
       "    'rank_score': 0.6247772169113159,\n",
       "    'excerpt': \"Training Simple Machine Learning Algorithms for Classification 30 First, we will use the pandas library to load the Iris dataset directly from the UCI Machine Learning Repository into a DataFrame object and print the last five lines via the tail method to check that the data was loaded correctly: >>> import os >>> import pandas as pd >>> s = 'https://archive.ics.uci.edu/ml/'\\\\ ... 'machine-learning-databases/iris/iris.data' >>> print('From URL:', s) From URL: https://archive.ics.uci.edu/ml/machin\"},\n",
       "   {'chunk_id': 'bc2e58fd-45f5-5427-8ae1-2e90d81279ff',\n",
       "    'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "    'section_path': [],\n",
       "    'order': 372,\n",
       "    'score': 0.37614548206329346,\n",
       "    'rank_score': 0.6128121487299601,\n",
       "    'excerpt': 'Implementing a Multilayer Artificial Neural Network from Scratch 350 ################################# # Part 2: dLoss/dHiddenWeights ## = DeltaOut * dOutNet/dHiddenAct * dHiddenAct/dHiddenNet # * dHiddenNet/dWeight # [n_classes, n_hidden] d_z_out__a_h = self.weight_out # output dim: [n_examples, n_hidden] d_loss__a_h = np.dot(delta_out, d_z_out__a_h) # [n_examples, n_hidden] d_a_h__d_z_h = a_h * (1. - a_h) # sigmoid derivative # [n_examples, n_features] d_z_h__d_w_h = x # output dim: [n_hidden,'}],\n",
       "  'raw': {'answer': \"The binary classification task involves using the softmax function to compute class probabilities from the neural network's output, ensalled by the argmax function for class label prediction. The softmax function normalizes the output of the network to ensure the sum of probabilities equals 1, which is essential for interpreting the network's output as class probabilities (6a6b2bde-ce69-5504-be91-9e2e71dc1fe9). For multi-class classification, the one-versus-rest (OvA) method extends binary classifiers to handle multiple classes by training a separate classifier for each class, assigning the class with the highest confidence score (49253f48-b666-5c03-acde-3d2484e44acc). The backward method in the NeuralNetMLP class computes gradients for the loss function, which are used for updating the network's parameters via gradient descent (bc2e58fd-45f5-5427-8ae1-2e90d81279ff).\\n\\n\\nDocument:\\n\\n- [6a6b2bde-ce69-5504-be91-9e2e71dc1fe9] Context\\n  Parallelizing Neural Network Training with PyTorch 40 After training a neural network with PyTorch, we can use the softmax function to convert the network's output into class probabilities. However, the output does not sum to 1, which is a problem for interpreting the network's output as class probabilities. Nevertheless, this is not a significant issue if we only use the network to predict class labels and not the class probabilities. One way to obtain class labels from the\",\n",
       "   'citations': [{'chunk_id': '6a6b2bde-ce69-5504-be91-9e2e71dc1fe9',\n",
       "     'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "     'section_path': [],\n",
       "     'order': 424,\n",
       "     'score': 0.37638697028160095,\n",
       "     'rank_score': 0.646386970281601,\n",
       "     'excerpt': 'Parallelizing Neural Network Training with PyTorch 402 As you can see in the output, the resulting values cannot be interpreted as probabilities for a three-class problem. The reason for this is that they do not sum to 1. However, this is, in fact, not a big concern if we use our model to predict only the class labels and not the class membership probabilities. One way to predict the class label from the output units obtained earlier is to use the maximum value: >>> y_class = np.argmax(Z, axis=0'},\n",
       "    {'chunk_id': '49253f48-b666-5c03-acde-3d2484e44acc',\n",
       "     'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "     'section_path': [],\n",
       "     'order': 56,\n",
       "     'score': 0.3547772169113159,\n",
       "     'rank_score': 0.6247772169113159,\n",
       "     'excerpt': \"Training Simple Machine Learning Algorithms for Classification 30 First, we will use the pandas library to load the Iris dataset directly from the UCI Machine Learning Repository into a DataFrame object and print the last five lines via the tail method to check that the data was loaded correctly: >>> import os >>> import pandas as pd >>> s = 'https://archive.ics.uci.edu/ml/'\\\\ ... 'machine-learning-databases/iris/iris.data' >>> print('From URL:', s) From URL: https://archive.ics.uci.edu/ml/machin\"},\n",
       "    {'chunk_id': 'bc2e58fd-45f5-5427-8ae1-2e90d81279ff',\n",
       "     'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "     'section_path': [],\n",
       "     'order': 372,\n",
       "     'score': 0.37614548206329346,\n",
       "     'rank_score': 0.6128121487299601,\n",
       "     'excerpt': 'Implementing a Multilayer Artificial Neural Network from Scratch 350 ################################# # Part 2: dLoss/dHiddenWeights ## = DeltaOut * dOutNet/dHiddenAct * dHiddenAct/dHiddenNet # * dHiddenNet/dWeight # [n_classes, n_hidden] d_z_out__a_h = self.weight_out # output dim: [n_examples, n_hidden] d_loss__a_h = np.dot(delta_out, d_z_out__a_h) # [n_examples, n_hidden] d_a_h__d_z_h = a_h * (1. - a_h) # sigmoid derivative # [n_examples, n_features] d_z_h__d_w_h = x # output dim: [n_hidden,'}],\n",
       "   'prompt': \"Context:\\n- [6a6b2bde-ce69-5504-be91-9e2e71dc1fe9] Context\\n  Parallelizing Neural Network Training with PyTorch 402 As you can see in the output, the resulting values cannot be interpreted as probabilities for a three-class problem. The reason for this is that they do not sum to 1. However, this is, in fact, not a big concern if we use our model to predict only the class labels and not the class membership probabilities. One way to predict the class label from the output units obtained earlier is to use the maximum value: >>> y_class = np.argmax(Z, axis=0) >>> print('Predicted class label:', y_class) Predicted class label: 0 In certain contexts, it can be useful to compute meaningful class probabilities for multiclass predic- tions. In the next section, we will take a look at a generalization of the logistic function, the softmax function, which can help us with this task. Estimating class probabilities in multiclass classification via the softmax function In the previous section, you saw how we can obtain a class label using the argmax function. Previously, in the Building a multilayer perceptron for classifying flowers in the Iris dataset section, we determined activation='softmax' in the last layer of the MLP model. The softmax function is a soft form of the argmax function; instead of giving a single class index, it provides the probability of each class. Therefore, it allows us to compute meaningful class probabilities in multiclass settings (multinomial logistic regression). In softmax, the probability of a particular sample with net input z belonging to the ith class can be computed with a normalization term in the denominator, that is, the sum of the exponentially weighted linear functions: () = () =      To see softmax in action, lets code it up in Python: >>> def softmax(z): ... return np.exp(z) / np.sum(np.exp(z)) >>> y_probas = softmax(Z) >>> print('Probabilities:\\\\n', y_probas) Probabilities: [ 0.44668973 0.16107406 0.39223621] >>> np.sum(y_probas) 1.0 As you can see, the predicted class probabilities now sum to 1, as we would expect. It is also notable that the predicted class label is the same as when we applied the argmax function to the logistic output.\\n- [49253f48-b666-5c03-acde-3d2484e44acc] Context\\n  Training Simple Machine Learning Algorithms for Classification 30 First, we will use the pandas library to load the Iris dataset directly from the UCI Machine Learning Repository into a DataFrame object and print the last five lines via the tail method to check that the data was loaded correctly: >>> import os >>> import pandas as pd >>> s = 'https://archive.ics.uci.edu/ml/'\\\\ ... 'machine-learning-databases/iris/iris.data' >>> print('From URL:', s) From URL: https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris. data >>> df = pd.read_csv(s, ... header=None, ... encoding='utf-8') >>> df.tail() After executing the previous code, we should see the following output, which shows the last five lines of the Iris dataset: Figure 2.5: The last five lines of the Iris dataset The OvA method for multi-class classification OvA, which is sometimes also called one-versus-rest (OvR), is a technique that allows us to extend any binary classifier to multi-class problems. Using OvA, we can train one classifier per class, where the particular class is treated as the positive class and the examples from all other classes are considered negative classes. If we were to classify a new, unlabeled data instance, we would use our n classifiers, where n is the number of class labels, and assign the class label with the highest confidence to the particular instance we want to classify. In the case of the perceptron, we would use OvA to choose the class label that is associated with the largest absolute net input value.\\n- [bc2e58fd-45f5-5427-8ae1-2e90d81279ff] Context\\n  Implementing a Multilayer Artificial Neural Network from Scratch 350 ################################# # Part 2: dLoss/dHiddenWeights ## = DeltaOut * dOutNet/dHiddenAct * dHiddenAct/dHiddenNet # * dHiddenNet/dWeight # [n_classes, n_hidden] d_z_out__a_h = self.weight_out # output dim: [n_examples, n_hidden] d_loss__a_h = np.dot(delta_out, d_z_out__a_h) # [n_examples, n_hidden] d_a_h__d_z_h = a_h * (1. - a_h) # sigmoid derivative # [n_examples, n_features] d_z_h__d_w_h = x # output dim: [n_hidden, n_features] d_loss__d_w_h = np.dot((d_loss__a_h * d_a_h__d_z_h).T, d_z_h__d_w_h) d_loss__d_b_h = np.sum((d_loss__a_h * d_a_h__d_z_h), axis=0) return (d_loss__dw_out, d_loss__db_out, d_loss__d_w_h, d_loss__d_b_h) The backward method implements the so-called backpropagation algorithm, which calculates the gra- dients of the loss with respect to the weight and bias parameters. Similar to Adaline, these gradients are then used to update these parameters via gradient descent. Note that multilayer NNs are more complex than their single-layer siblings, and we will go over the mathematical concepts of how to compute the gradients in a later section after discussing the code. For now, just consider the backward method as a way for computing gradients that are used for the gradient descent updates. For simplic- ity, the loss function this derivation is based on is the same MSE loss that we used in Adaline. In later chapters, we will look at alternative loss functions, such as multi-category cross-entropy loss, which is a generalization of the binary logistic regression loss to multiple classes. Looking at this code implementation of the NeuralNetMLP class, you may have noticed that this object-oriented implementation differs from the familiar scikit-learn API that is centered around the .fit() and .predict() methods. Instead, the main methods of the NeuralNetMLP class are the .forward() and .backward() methods. One of the reasons behind this is that it makes a complex neu- ral network a bit easier to understand in terms of how the information flows through the networks.\\n\\nQuestion: Summarize the key binary classification task .\\n\\nAnswer in at most four sentences and cite sources using [chunk_id].\",\n",
       "   'system_prompt': 'You are a precise assistant. Use only the provided context to answer. Respond succinctly, cite sources using their [chunk_id] identifiers, and do not introduce facts that are not present in the context.',\n",
       "   'evidence': [{'chunk_id': '6a6b2bde-ce69-5504-be91-9e2e71dc1fe9',\n",
       "     'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "     'order': 424,\n",
       "     'text': \"Parallelizing Neural Network Training with PyTorch 402 As you can see in the output, the resulting values cannot be interpreted as probabilities for a three-class problem. The reason for this is that they do not sum to 1. However, this is, in fact, not a big concern if we use our model to predict only the class labels and not the class membership probabilities. One way to predict the class label from the output units obtained earlier is to use the maximum value: >>> y_class = np.argmax(Z, axis=0) >>> print('Predicted class label:', y_class) Predicted class label: 0 In certain contexts, it can be useful to compute meaningful class probabilities for multiclass predic- tions. In the next section, we will take a look at a generalization of the logistic function, the softmax function, which can help us with this task. Estimating class probabilities in multiclass classification via the softmax function In the previous section, you saw how we can obtain a class label using the argmax function. Previously, in the Building a multilayer perceptron for classifying flowers in the Iris dataset section, we determined activation='softmax' in the last layer of the MLP model. The softmax function is a soft form of the argmax function; instead of giving a single class index, it provides the probability of each class. Therefore, it allows us to compute meaningful class probabilities in multiclass settings (multinomial logistic regression). In softmax, the probability of a particular sample with net input z belonging to the ith class can be computed with a normalization term in the denominator, that is, the sum of the exponentially weighted linear functions: () = () =      To see softmax in action, lets code it up in Python: >>> def softmax(z): ... return np.exp(z) / np.sum(np.exp(z)) >>> y_probas = softmax(Z) >>> print('Probabilities:\\\\n', y_probas) Probabilities: [ 0.44668973 0.16107406 0.39223621] >>> np.sum(y_probas) 1.0 As you can see, the predicted class probabilities now sum to 1, as we would expect. It is also notable that the predicted class label is the same as when we applied the argmax function to the logistic output.\",\n",
       "     'section_path': [],\n",
       "     'text_hash': 'f4d29b06a3c96a45c2aaf84a230fb3a9975640b77586cf8ca0e5c6741637bdd2',\n",
       "     'score': 0.37638697028160095,\n",
       "     'rank_score': 0.646386970281601},\n",
       "    {'chunk_id': '49253f48-b666-5c03-acde-3d2484e44acc',\n",
       "     'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "     'order': 56,\n",
       "     'text': \"Training Simple Machine Learning Algorithms for Classification 30 First, we will use the pandas library to load the Iris dataset directly from the UCI Machine Learning Repository into a DataFrame object and print the last five lines via the tail method to check that the data was loaded correctly: >>> import os >>> import pandas as pd >>> s = 'https://archive.ics.uci.edu/ml/'\\\\ ... 'machine-learning-databases/iris/iris.data' >>> print('From URL:', s) From URL: https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris. data >>> df = pd.read_csv(s, ... header=None, ... encoding='utf-8') >>> df.tail() After executing the previous code, we should see the following output, which shows the last five lines of the Iris dataset: Figure 2.5: The last five lines of the Iris dataset The OvA method for multi-class classification OvA, which is sometimes also called one-versus-rest (OvR), is a technique that allows us to extend any binary classifier to multi-class problems. Using OvA, we can train one classifier per class, where the particular class is treated as the positive class and the examples from all other classes are considered negative classes. If we were to classify a new, unlabeled data instance, we would use our n classifiers, where n is the number of class labels, and assign the class label with the highest confidence to the particular instance we want to classify. In the case of the perceptron, we would use OvA to choose the class label that is associated with the largest absolute net input value.\",\n",
       "     'section_path': [],\n",
       "     'text_hash': 'f66ea4b7d32d6a9341dcc3ac1d396ffb38420dd22c2efb5e8174746a1d9464b1',\n",
       "     'score': 0.3547772169113159,\n",
       "     'rank_score': 0.6247772169113159},\n",
       "    {'chunk_id': 'bc2e58fd-45f5-5427-8ae1-2e90d81279ff',\n",
       "     'doc_id': 'f33d29ea-5935-4606-8342-c4e11496f63f',\n",
       "     'order': 372,\n",
       "     'text': 'Implementing a Multilayer Artificial Neural Network from Scratch 350 ################################# # Part 2: dLoss/dHiddenWeights ## = DeltaOut * dOutNet/dHiddenAct * dHiddenAct/dHiddenNet # * dHiddenNet/dWeight # [n_classes, n_hidden] d_z_out__a_h = self.weight_out # output dim: [n_examples, n_hidden] d_loss__a_h = np.dot(delta_out, d_z_out__a_h) # [n_examples, n_hidden] d_a_h__d_z_h = a_h * (1. - a_h) # sigmoid derivative # [n_examples, n_features] d_z_h__d_w_h = x # output dim: [n_hidden, n_features] d_loss__d_w_h = np.dot((d_loss__a_h * d_a_h__d_z_h).T, d_z_h__d_w_h) d_loss__d_b_h = np.sum((d_loss__a_h * d_a_h__d_z_h), axis=0) return (d_loss__dw_out, d_loss__db_out, d_loss__d_w_h, d_loss__d_b_h) The backward method implements the so-called backpropagation algorithm, which calculates the gra- dients of the loss with respect to the weight and bias parameters. Similar to Adaline, these gradients are then used to update these parameters via gradient descent. Note that multilayer NNs are more complex than their single-layer siblings, and we will go over the mathematical concepts of how to compute the gradients in a later section after discussing the code. For now, just consider the backward method as a way for computing gradients that are used for the gradient descent updates. For simplic- ity, the loss function this derivation is based on is the same MSE loss that we used in Adaline. In later chapters, we will look at alternative loss functions, such as multi-category cross-entropy loss, which is a generalization of the binary logistic regression loss to multiple classes. Looking at this code implementation of the NeuralNetMLP class, you may have noticed that this object-oriented implementation differs from the familiar scikit-learn API that is centered around the .fit() and .predict() methods. Instead, the main methods of the NeuralNetMLP class are the .forward() and .backward() methods. One of the reasons behind this is that it makes a complex neu- ral network a bit easier to understand in terms of how the information flows through the networks.',\n",
       "     'section_path': [],\n",
       "     'text_hash': '052c60f6dd5f60e8a31732174fe8e6ac84314f5d24bd580b25a1d563547365e6',\n",
       "     'score': 0.37614548206329346,\n",
       "     'rank_score': 0.6128121487299601}]}}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "benchmark_results: list[dict[str, object]] = []\n",
    "man_ctx = MANUAL_CONTEXT or None\n",
    "\n",
    "for run in TRAINING_RUNS:\n",
    "    adapter_dir = run.get(\"adapter_dir\")\n",
    "    if adapter_dir is None:\n",
    "        raise RuntimeError(f\"Adapter directory missing for run {run['name']}\")\n",
    "\n",
    "    print(f\"=== Benchmarking {run['name']} ===\")\n",
    "    response = ask_with_adapter(ASK_CONFIG, adapter_dir=adapter_dir, manual_context=man_ctx)\n",
    "    benchmark_results.append({\n",
    "        \"name\": run[\"name\"],\n",
    "        \"answer\": response[\"answer\"],\n",
    "        \"citations\": response.get(\"citations\", []),\n",
    "        \"raw\": response,\n",
    "    })\n",
    "    print(\"Answer (wrapped to 100 chars):\")\n",
    "    print(textwrap.fill(response[\"answer\"], width=100))\n",
    "    if response.get(\"citations\"):\n",
    "        for c in response[\"citations\"]:\n",
    "            rank = c.get(\"rank_score\") or c.get(\"score\") or 0.0\n",
    "            print(f\"- [{c.get('chunk_id')}] order={c.get('order')} rank={rank:.3f}\")\n",
    "    else:\n",
    "        print(\"(no citations returned)\")\n",
    "\n",
    "benchmark_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a5fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
