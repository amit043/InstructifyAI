
x-gpu-env: &gpu_env
  NVIDIA_VISIBLE_DEVICES: "all"
  NVIDIA_DRIVER_CAPABILITIES: "compute,utility"

x-build-api: &build_api
  context: .
  dockerfile: Dockerfile
  args:
    INSTALL_ML: "0"

x-build-ml: &build_ml
  context: .
  dockerfile: Dockerfile
  args:
    INSTALL_ML: "1"
    ML_VARIANT: ${ML_VARIANT:-cpu}
    HF_PREFETCH: "0"
    HF_MODEL: ${BASE_MODEL:-microsoft/Phi-3-mini-4k-instruct}

x-build-worker: &build_worker
  context: .
  dockerfile: docker/Dockerfile.worker

x-build-worker-ocr: &build_worker_ocr
  context: .
  dockerfile: docker/Dockerfile.worker-ocr

x-default-env-file: &default_env_file
  - .env

x-default-depends: &default_depends
  postgres:
    condition: service_healthy
  redis:
    condition: service_healthy
  minio:
    condition: service_healthy

services:

  postgres:
    image: postgres:15
    environment:
      POSTGRES_PASSWORD: labeler
      POSTGRES_USER: labeler
      POSTGRES_DB: labeler
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U labeler"]
      interval: 10s
      retries: 5

  redis:
    image: redis:7
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      retries: 5

  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      retries: 5

  api:
    image: instructify-api:latest
    build: *build_api
    ports:
      - "8000:8000"
    env_file: *default_env_file
    environment:
      ENABLE_ADAPTERS_API: "true"
    depends_on: *default_depends
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      retries: 5
    volumes:
      - .:/app
      - hf-cache:/root/.cache/huggingface

  worker:
    image: instructify-worker:latest
    build: *build_worker
    command: celery -A worker.main worker --loglevel=info -Q celery
    env_file: *default_env_file
    depends_on: *default_depends
    healthcheck:
      test: ["CMD-SHELL", "celery -A worker.main inspect ping -t 1 > /dev/null"]
      interval: 10s
      retries: 5
    volumes:
      - .:/app

  worker_ocr:
    image: instructify-worker-ocr:latest
    build: *build_worker_ocr
    command: celery -A worker.main worker --loglevel=info -Q ocr -c ${OCR_WORKER_CONCURRENCY:-1}
    env_file: *default_env_file
    depends_on: *default_depends
    healthcheck:
      test: ["CMD-SHELL", "celery -A worker.main inspect ping -t 1 > /dev/null"]
      interval: 10s
      retries: 5
    volumes:
      - .:/app

  gen:
    image: instructify-ml:latest
    build: *build_ml
    command: bash -lc "python scripts/serve_local.py"
    env_file: *default_env_file
    environment:
      BASE_BACKEND: "hf"
      HF_HOME: "/opt/hf"
      TRANSFORMERS_CACHE: "/opt/hf"
      ML_VARIANT: ${ML_VARIANT:-cpu}
      HF_MODEL: ${BASE_MODEL:-microsoft/Phi-3-mini-4k-instruct}
      <<: *gpu_env
    depends_on: *default_depends
    ports:
      - "9009:9009"
    volumes:
      - .:/app
      - hf-cache:/opt/hf
    # GPU reservations removed for Podman (CDI not configured). Use override file to enable GPU.

  trainer:
    image: instructify-ml:latest
    build: *build_ml
    command: bash -lc "tail -f /dev/null"
    env_file: *default_env_file
    depends_on: *default_depends
    profiles: ["train"]
    environment:
      HF_HOME: "/opt/hf"
      TRANSFORMERS_CACHE: "/opt/hf"
      ML_VARIANT: ${ML_VARIANT:-cpu}
      HF_MODEL: ${BASE_MODEL:-microsoft/Phi-3-mini-4k-instruct}
      <<: *gpu_env
    volumes:
      - .:/app
      - hf-cache:/opt/hf
    # GPU reservations removed for Podman (CDI not configured). Use override file to enable GPU.

  flower:
    image: instructify-worker:latest
    command: celery -A worker.main flower --port=5555
    env_file: *default_env_file
    environment:
      CELERY_BROKER_URL: ${REDIS_URL:-redis://redis:6379/0}
    depends_on:
      redis:
        condition: service_healthy
    ports:
      - "5555:5555"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5555/"]
      interval: 10s
      retries: 10
    volumes:
      - .:/app

  labelstudio:
    image: heartexlabs/label-studio:latest
    ports:
      - "8080:8080"
    volumes:
      - ls-data:/label-studio/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      retries: 10

volumes:
  hf-cache:
  postgres-data:
  redis-data:
  minio-data:
  ls-data:
